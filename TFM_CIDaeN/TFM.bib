
@article{MoViNets,
  author    = {Dan Kondratyuk and
               Liangzhe Yuan and
               Yandong Li and
               Li Zhang and
               Mingxing Tan and
               Matthew Brown and
               Boqing Gong},
  title     = {MoViNets: Mobile Video Networks for Efficient Video Recognition},
  journal   = {CoRR},
  volume    = {abs/2103.11511},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.11511},
  eprinttype = {arXiv},
  eprint    = {2103.11511},
  timestamp = {Wed, 24 Mar 2021 15:50:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-11511.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{I3D,
  author    = {Jo{\~{a}}o Carreira and
               Andrew Zisserman},
  title     = {Quo Vadis, Action Recognition? {A} New Model and the Kinetics Dataset},
  journal   = {CoRR},
  volume    = {abs/1705.07750},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.07750},
  eprinttype = {arXiv},
  eprint    = {1705.07750},
  timestamp = {Mon, 13 Aug 2018 16:47:23 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/CarreiraZ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{X3D,
  author    = {Christoph Feichtenhofer},
  title     = {{X3D:} Expanding Architectures for Efficient Video Recognition},
  journal   = {CoRR},
  volume    = {abs/2004.04730},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.04730},
  eprinttype = {arXiv},
  eprint    = {2004.04730},
  timestamp = {Tue, 14 Apr 2020 16:40:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-04730.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{UCF101,
  author    = {Khurram Soomro and
               Amir Roshan Zamir and
               Mubarak Shah},
  title     = {{UCF101:} {A} Dataset of 101 Human Actions Classes From Videos in
               The Wild},
  journal   = {CoRR},
  volume    = {abs/1212.0402},
  year      = {2012},
  url       = {http://arxiv.org/abs/1212.0402},
  eprinttype = {arXiv},
  eprint    = {1212.0402},
  timestamp = {Mon, 13 Aug 2018 16:47:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1212-0402.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{Kinetics400,
  author    = {Will Kay and
               Jo{\~{a}}o Carreira and
               Karen Simonyan and
               Brian Zhang and
               Chloe Hillier and
               Sudheendra Vijayanarasimhan and
               Fabio Viola and
               Tim Green and
               Trevor Back and
               Paul Natsev and
               Mustafa Suleyman and
               Andrew Zisserman},
  title     = {The Kinetics Human Action Video Dataset},
  journal   = {CoRR},
  volume    = {abs/1705.06950},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.06950},
  eprinttype = {arXiv},
  eprint    = {1705.06950},
  timestamp = {Thu, 14 Oct 2021 09:15:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KayCSZHVVGBNSZ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{Kinetics600,
  author    = {Jo{\~{a}}o Carreira and
               Eric Noland and
               Andras Banki{-}Horvath and
               Chloe Hillier and
               Andrew Zisserman},
  title     = {A Short Note about Kinetics-600},
  journal   = {CoRR},
  volume    = {abs/1808.01340},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.01340},
  eprinttype = {arXiv},
  eprint    = {1808.01340},
  timestamp = {Sun, 02 Sep 2018 15:01:55 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-01340.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{Merlot,
  author    = {Rowan Zellers and
               Jiasen Lu and
               Ximing Lu and
               Youngjae Yu and
               Yanpeng Zhao and
               Mohammadreza Salehi and
               Aditya Kusupati and
               Jack Hessel and
               Ali Farhadi and
               Yejin Choi},
  title     = {{MERLOT} Reserve: Neural Script Knowledge through Vision and Language
               and Sound},
  journal   = {CoRR},
  volume    = {abs/2201.02639},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.02639},
  eprinttype = {arXiv},
  eprint    = {2201.02639},
  timestamp = {Thu, 20 Jan 2022 14:21:35 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-02639.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{FitnessMovementTypes,
AUTHOR = {Chen, Kuan-Yu and Shin, Jungpil and Hasan, Md. Al Mehedi and Liaw, Jiun-Jian and Yuichi, Okuyama and Tomioka, Yoichi},
TITLE = {Fitness Movement Types and Completeness Detection Using a Transfer-Learning-Based Deep Neural Network},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {15},
ARTICLE-NUMBER = {5700},
URL = {https://www.mdpi.com/1424-8220/22/15/5700},
PubMedID = {35957257},
ISSN = {1424-8220},
ABSTRACT = {Fitness is important in people&rsquo;s lives. Good fitness habits can improve cardiopulmonary capacity, increase concentration, prevent obesity, and effectively reduce the risk of death. Home fitness does not require large equipment but uses dumbbells, yoga mats, and horizontal bars to complete fitness exercises and can effectively avoid contact with people, so it is deeply loved by people. People who work out at home use social media to obtain fitness knowledge, but learning ability is limited. Incomplete fitness is likely to lead to injury, and a cheap, timely, and accurate fitness detection system can reduce the risk of fitness injuries and can effectively improve people&rsquo;s fitness awareness. In the past, many studies have engaged in the detection of fitness movements, among which the detection of fitness movements based on wearable devices, body nodes, and image deep learning has achieved better performance. However, a wearable device cannot detect a variety of fitness movements, may hinder the exercise of the fitness user, and has a high cost. Both body-node-based and image-deep-learning-based methods have lower costs, but each has some drawbacks. Therefore, this paper used a method based on deep transfer learning to establish a fitness database. After that, a deep neural network was trained to detect the type and completeness of fitness movements. We used Yolov4 and Mediapipe to instantly detect fitness movements and stored the 1D fitness signal of movement to build a database. Finally, MLP was used to classify the 1D signal waveform of fitness. In the performance of the classification of fitness movement types, the mAP was 99.71%, accuracy was 98.56%, precision was 97.9%, recall was 98.56%, and the F1-score was 98.23%, which is quite a high performance. In the performance of fitness movement completeness classification, accuracy was 92.84%, precision was 92.85, recall was 92.84%, and the F1-score was 92.83%. The average FPS in detection was 17.5. Experimental results show that our method achieves higher accuracy compared to other methods.},
DOI = {10.3390/s22155700}
}


@article{ClassifyFunctionalFitness,
author = {Preatoni, Ezio and Nodari, Stefano and Lopomo, Nicola Francesco},
year = {2020},
month = {07},
pages = {664},
title = {Supervised Machine Learning Applied to Wearable Sensor Data Can Accurately Classify Functional Fitness Exercises Within a Continuous Workout},
volume = {8},
journal = {Frontiers in Bioengineering and Biotechnology},
doi = {10.3389/fbioe.2020.00664}
}


@article{Yolo4,
  author    = {Alexey Bochkovskiy and
               Chien{-}Yao Wang and
               Hong{-}Yuan Mark Liao},
  title     = {YOLOv4: Optimal Speed and Accuracy of Object Detection},
  journal   = {CoRR},
  volume    = {abs/2004.10934},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.10934},
  eprinttype = {arXiv},
  eprint    = {2004.10934},
  timestamp = {Tue, 28 Apr 2020 16:10:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-10934.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
